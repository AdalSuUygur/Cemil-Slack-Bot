import os
from typing import List, Dict, Any
from langchain_text_splitters import RecursiveCharacterTextSplitter
from pypdf import PdfReader
from src.core.logger import logger
from src.clients import VectorClient, GroqClient

class KnowledgeService:
    """
    Cemil'in 'Bilgi KÃ¼pÃ¼' (RAG). DÃ¶kÃ¼manlarÄ± iÅŸler ve sorularÄ± yanÄ±tlar.
    Tamamen Ã¼cretsiz ve limit-free yapÄ±dadÄ±r.
    """

    def __init__(self, vector_client: VectorClient, groq_client: GroqClient):
        self.vector = vector_client
        self.groq = groq_client
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=700,
            chunk_overlap=100
        )

    async def process_knowledge_base(self, folder_path: str = "knowledge_base"):
        """Belirtilen klasÃ¶rdeki dÃ¶kÃ¼manlarÄ± okur ve indekse ekler."""
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)
            logger.warning(f"[!] {folder_path} bulunamadÄ±, boÅŸ bir tane oluÅŸturuldu.")
            return

        all_texts = []
        all_metadata = []

        for filename in os.listdir(folder_path):
            file_path = os.path.join(folder_path, filename)
            text = ""
            
            try:
                if filename.endswith(".pdf"):
                    reader = PdfReader(file_path)
                    for page in reader.pages:
                        text += page.extract_text() + "\n"
                elif filename.endswith(".txt"):
                    with open(file_path, "r", encoding="utf-8") as f:
                        text = f.read()
                
                if text.strip():
                    chunks = self.splitter.split_text(text)
                    all_texts.extend(chunks)
                    all_metadata.extend([{"source": filename}] * len(chunks))
                    logger.info(f"[+] Ä°ÅŸlendi: {filename} ({len(chunks)} parÃ§a)")

            except Exception as e:
                logger.error(f"[X] {filename} iÅŸlenirken hata: {e}")

        if all_texts:
            self.vector.add_texts(all_texts, all_metadata)
            logger.info(f"[!] {len(all_texts)} parÃ§a ile Bilgi KÃ¼pÃ¼ gÃ¼ncellendi.")

    async def ask_question(self, question: str) -> str:
        """KullanÄ±cÄ±nÄ±n sorusunu dÃ¶kÃ¼manlara gÃ¶re yanÄ±tlar."""
        try:
            # 1. Benzer metin parÃ§alarÄ±nÄ± bul
            context_docs = self.vector.search(question, top_k=4)
            
            if not context_docs:
                return "ÃœzgÃ¼nÃ¼m, bu konuda bilgi kÃ¼pÃ¼mde herhangi bir veri bulamadÄ±m. ğŸ˜”"

            # 2. BaÄŸlamÄ± (Context) hazÄ±rla
            context_text = "\n\n".join([
                f"--- Kaynak: {doc['metadata'].get('source', 'Bilinmiyor')} ---\n{doc['text']}" 
                for doc in context_docs
            ])

            # 3. LLM'e (Groq) sor
            system_prompt = (
                "Sen Cemil'sin, topluluk asistanÄ±sÄ±n. AÅŸaÄŸÄ±da sana verilen BAÄLAM (Context) bilgilerini kullanarak "
                "kullanÄ±cÄ±nÄ±n sorusunu yanÄ±tla. Sadece saÄŸlanan bilgileri kullan. EÄŸer cevap baÄŸlamda yoksa "
                "kibarca bilmediÄŸini sÃ¶yle. YanÄ±tlarÄ±n samimi, Ã¶z ve ASCII karakterlerle (emojisiz) olsun."
            )
            
            user_prompt = f"BAÄLAM:\n{context_text}\n\nSORU: {question}"
            
            answer = await self.groq.quick_ask(system_prompt, user_prompt)
            return answer

        except Exception as e:
            logger.error(f"[X] KnowledgeService.ask_question hatasÄ±: {e}")
            return "Zeka katmanÄ±mda bir sorun oluÅŸtu, lÃ¼tfen daha sonra tekrar dene. [X]"
